<!DOCTYPE html>
<html>
<head>
  <title>Capstone Project</title>
  <meta charset="utf-8"/>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
  <link href='https://fonts.googleapis.com/css?family=Roboto:300,400,700' rel='stylesheet' type='text/css'>


  <link rel="stylesheet" type="text/css" href="capstone.css">
</head>
<body>
<header class="container">
  <div class="row">
    <h1 class="col-sm-4">Oussama Belhenniche</h1>
    <nav class="col-sm-8 text-right">
    <a href="/index.html">HOME</a>
    <a href="/about/index.html">ABOUT</a>
    <a href="/projects/index.html">PROJECTS</a>
    <a href="/blog/index.html">BLOG</a>

    </nav>
 	</div>
</header>

</br>
<div class="container">
    <div class="page-header">
<h1>Video Guidance System for Automated Drone Flight</h1>
    </div>
<p>Landing a drone accurately is the hardest part about operating it, especially
   if the operator is far from the landing zone. The goal behind this project is
    to automate the process of landing. The system is designed to “talk” to the
    drone to try to center it with the right orientation and then proceed to
    send the control signal for the landing subroutine.  </p>
    <div class="page-header">
      <h3>Hardware:</h3>
    </div>
    <figure>
      <img class="center-block" src="/contents/images/projects/capstone/hardware_block_diagram.png"   style="width:80%" >
      <figcaption class="text-center">Hardware block diagram of the system </figcaption>
    </figure>
</br></br>
  <p>The hardware was comprised of a portable processing unit, in this case we used a
    <a href="https://en.wikipedia.org/wiki/Raspberry_Pi">Raspberry Pi</a>, and an image sensor, which was a simple <a href="https://www.raspberrypi.org/products/camera-module/"> Raspberry Pi camera</a>.
    To help identify the drone an LEDs attachment is attached to the bottom of the drone. The LEDs were configured in non-symmetrical way for direction
    recognition (to know which way the drone is pointing).
The communication between the drone attachment and Raspberry Pi was established using Xbees.
</p>
</br>

<div class="row">

  <div class="col-sm-5">
    <img class= "center-block"src="/contents/images/projects/capstone/sketch_drone.png"   style="width:90%" >
    <figcaption class="text-left" style="text-indent: 7em">LEDs attachment sketch</figcaption>
  </div>

<div class="col-sm-1"></div><!-- Just to have space between the two pictures-->

<div class="col-sm-5">
  <img class= "center-block" src="/contents/images/projects/capstone/hardware_atta.png"   style="width:100%" >
  <figcaption class="text-left" style="text-indent:12em"> LEDs attachment</figcaption>
</div>

</div>


</br></br>
<div class="row">

  <div class="col-sm-5">
    <img class= "center-block"src="/contents/images/projects/capstone/circuit_diag_pi.png"   style="width:100%" >
    <figcaption class="text-left" style="text-indent: 7em">Circuit diagram of the Raspberry Pi</figcaption>
  </div>

<div class="col-sm-1"></div><!-- Just to have space between the two pictures-->

<div class="col-sm-5">
  <img class= "center-block" src="/contents/images/projects/capstone/circuit_diag_drone_att.png"   style="width:87%" >
  <figcaption class="text-left" style="text-indent:12em"> Circuit diagram of drone's attachment</figcaption>
</div>

</div>



</br>

<div class="Software">

  <div class="page-header">
    <h3>Software:</h3>
  </div>
  <figure class="figure">
    <img class="center-block" src="/contents/images/projects/capstone/software_blck_diagram.png" style="width:80%">
    <figcaption class="text-center"> Software block diagram</figcaption>
  </figure>
</br>
<p>The Software that was developed was a mixture of image processing (filtering, thresholding, convolution) and machine learning (k-means).</p>

<div clas="image-preprocessing">

<div class="page-header"><h4></br>Image Preprocessing:</h4>
</div>
<p>The first thing the algorithm does is to filter the static noise (i.e. sun, or a source of light)
   that could be mistaken by the software as an LED. To filter out the noise the algorithm
   takes two successive images, one with the LEDs ON, and another with the LEDs OFF, then perform
   image subtraction so that we are only left  with the LEDs.
To achieve this, the LEDs has to be flashed at the same frequency as the camera's frequency of taking pictures
</p>
</br>
<div class="row">

  <div class="col-sm-4">
      <img class="center-block" src="/contents/images/projects/capstone/leds_off.png" style="width:100%">
      <figcaption class="text-center">LEDs OFF with Noise presence</figcaption>
  </div>

  <div class="col-sm-4">
      <img class="center-block" src="/contents/images/projects/capstone/leds_ON.png" style="width:100%">
      <figcaption class="text-center">LEDs ON with Noise presence</figcaption>

  </div>

  <div class="col-sm-4">
      <img class="center-block" src="/contents/images/projects/capstone/leds_result.png" style="width:100%" >
      <figcaption class="text-center">LEDs ON with No Noise presence</figcaption>

  </div>
</div>
</br></br>
<p> To accentuate the LEDs and minimize the surrounding, a <a href="https://en.wikipedia.org/wiki/Template_matching">Template-matching </a>with a
  Gaussian filter is performed on the image.</p>

</br></br>
<div class="row">

<div class="col-sm-6">
  <img class="center-block" src="/contents/images/projects/capstone/gaussian_filter.png" style="width: 40%">
  <figcaption class="text-center"> Gaussian Filter kernel</figcaption>
 </div>

<div class="col-sm-6">
  <img class="center-block" src="/contents/images/projects/capstone/after_template_matching.png" style="width: 50%">
  <figcaption class="text-center"> Image after Template-matching</figcaption>

</div>
</div>
</br></br>







</div>
<div class"K-means">
<div class="page-header"><h4>K-Means:</h4></div>
<p> The <a href="https://en.wikipedia.org/wiki/K-means_clustering">K-means</a> algorithm is used to cluster
  the bright pixels (i.e. LEDs) together so that the processing afterwards will
  have less pixels to work with, thus making it less computationally intensive.
  The basic idea behind K-means clustering is grouping points that are closer to a given centroids (randomly generated points),
  how close the points are to a certain centroid depends on their <a href="https://en.wikipedia.org/wiki/Euclidean_distance">Euclidean distance</a>
  to that centroid compared to other centroids.
</p>

<img class="center-block" src="/contents/images/projects/capstone/kmeans.gif"  style="width:50%">
<figcaption class="text-center">K-means with 4 centroids</figcaption>
</div>
</br>

<div class="L-shape search">
<div class="page-header"><h4>Collinearity and L-shape search:</h4></div>
<p>Collinearity and L-shape search are the recognition phase of
  the algorithm. The configuration of the LEDs was chosen for easy identification
  of drone position and orientation. After clustering the bright pixels using the
  K-means algorithm, the system begins to search for the points (i.e bright spots)
  that are collinear (i.e. in a straight line). Then begins to search for the L-shape
  that distinguishes the drone position from any possible noise. After finding the collinear points,
  the algorithm loops through every triplet and searches for a centroid at right angles to the line of collinearity.
After locating the L-shape that the LEDs form, the algorithm draws an 'L' and superimpose it on the actual shape.
 </p>
 </br>
<img class="center-block" src="/contents/images/projects/capstone/coll_search.png">
<figcaption class="text-center">Collinearity search</figcaption>
</br>
<img class="center-block" src="/contents/images/projects/capstone/final_image_.png" style="width:40%">
<figcaption class="text-center">Superimposed 'L' on the position and direction of the drone attachment (drone)</figcaption>
</div>

</div>
</br></br></br></br></br>

<iframe class="center-block" src="https://drive.google.com/file/d/0BwKLN1QDadywSkliNWRNRzljaDg/preview" width="640" height="480"></iframe>
<figcaption class="text-center">Little demnstration of the LEDs attachement in action</figcaption>

</br></br></br></br>
<div class="page-header"></div>
</br></br></br>
</div> <!--Container ENDS! -->



</br>


















<footer class="container">
  <div class="row">
  <p class="col-sm-4"> &copy; Oussama Belhenniche </p>
    <ul class="col-sm-8">
      <li class="col-sm-1"><a href="about.html"> <img src="https://upload.wikimedia.org/wikipedia/commons/c/ce/Linkedin_circle.svg" /></a></li>
      <li class="col-sm-1"><a href="about.html"> <img src="https://upload.wikimedia.org/wikipedia/en/9/9f/Twitter_bird_logo_2012.svg" /></a></li>



    </ul>
  </div>


  </footer>





</body>
</html>
